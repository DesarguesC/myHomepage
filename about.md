---
layout: page
title: Personal Statements
permalink: /about/
---


I have been involved in research since the first semester of my sophomore year (2022.9). I was suspended in high school for mathematical competition in the first two years and I am now interested in deep learning theories and multimodal learning. My tutor suggested that I learn about Diffusion Models for their high relevance to mathematics and also to catch the researcher’s attention. So that is where I started my academic career.

Starting from learning principles of Diffusion Models, especially the Evidence Lower Bound of the Variational Diffusion Model, I was curious about the derivation process and was inspired by the idea of the upper bound optimization. That’s why I proved an optimization upper bound on the joint ControlNet framework, which can further improve the recognition of conditions in LDMs. At that period, I started to think that one of the important problems in Diffusion is actually "how to add constraints". This idea led me to learn more about related works, which later led me to do research in image editing.

And during this period I learned about approaches such as Instruct-Pix2Pix, SDEdit, Prompt2Prompt, etc. As I implemented their method, the weakness in previous work has exposed that though notable success they have gained in global optimization (to do transformation), their approaches fail to accomplish instance-level editing. That’s why I started to deal with the problem, thus writing our method into the paper named “Instance-Level Image Editing with LLM Agent”, which outperforms previous work, ranging from SDEdit, InstructPix2Pix[UC Berkeley, ICCV’23, Oral] to MGIE[Apple, ICML’24, Spotlight] in 5 metrics including CLIP Score, etc.

Simultaneously, due to the need for GPU renting, I also applied for several research projects and received nearly 60,000 yuan of funding support (about 10,000 yuan available at the moment ), while the cost of OpenAI, Anthropic, and other API calls is still at my own expense. I was interested in 3D synthesis (e.g. DreamFusion, Instruct-Nerf2Nerf, Profilic Dreamer, etc.) at the beginning of the year 2023, however, it is difficult to implement such research further still due to the limitations of GPUs. 

However, I was able to gain a better understanding of 3D synthesis and volume rendering while working with a doctoral student of the State Key Laboratory of CAD&CG (VAI Group), Zhejiang University. In the domain of scientific visualization, a MipMap-like method for dimensionality reduction of voxel data was implemented, while a differentiable voxel splatting engine was developed to provide controllable sensory fields for voxels with a footprint function mechanism. This scientific experience further deepened my understanding of volume rendering as well as 3D synthesis. 





[jekyll-organization]: https://github.com/jekyll

<!-- This is the base Jekyll theme. You can find out more info about customizing your Jekyll theme, as well as basic Jekyll usage documentation at [jekyllrb.com](https://jekyllrb.com/)

You can find the source code for Minima at GitHub:
[jekyll][jekyll-organization] /
[minima](https://github.com/jekyll/minima)

You can find the source code for Jekyll at GitHub:
[jekyll][jekyll-organization] /
[jekyll](https://github.com/jekyll/jekyll) -->
